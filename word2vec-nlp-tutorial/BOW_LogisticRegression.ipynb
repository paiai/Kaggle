{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/discussion/11261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/labeledTrainData.tsv\", header=0, delimiter='\\t', quoting=3)\n",
    "test = pd.read_csv(\"data/testData.tsv\", header=0, delimiter='\\t', quoting=3)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
    "\n",
    "# traindata = []\n",
    "# for i in range( 0, len(train[\"review\"])):\n",
    "#     traindata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(train[\"review\"][i], False)))\n",
    "# testdata = []\n",
    "# for i in range(0,len(test[\"review\"])):\n",
    "#     testdata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(test[\"review\"][i], False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82.8 ms, sys: 128 ms, total: 211 ms\n",
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "%time train['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(train['review'], KaggleWord2VecUtility.review_to_join_words, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87.5 ms, sys: 174 ms, total: 262 ms\n",
      "Wall time: 36.3 s\n"
     ]
    }
   ],
   "source": [
    "%time test['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(test['review'], KaggleWord2VecUtility.review_to_join_words, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train['review_clean']\n",
    "X_test = test['review_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "#                              strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "#                              ngram_range=(1, 2), use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "#                              stop_words='english')\n",
    "\n",
    "# vectorizer.fit(X_all)\n",
    "# X_train = vectorizer.transform(X_train)\n",
    "# X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 1.85 s, total: 1min 30s\n",
      "Wall time: 1min 31s\n",
      "CPU times: user 54.1 s, sys: 1.12 s, total: 55.2 s\n",
      "Wall time: 55.7 s\n",
      "CPU times: user 51.4 s, sys: 738 ms, total: 52.1 s\n",
      "Wall time: 52.2 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# char_vectorizer = Pipeline([('tfidf_char', TfidfVectorizer(\n",
    "#     analyzer='char', max_features=10000, ngram_range=(1, 9))) ])\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "                    sublinear_tf=True,\n",
    "                    strip_accents='unicode',\n",
    "                    analyzer='char',\n",
    "                    ngram_range=(1, 4),\n",
    "                    max_features=20000)\n",
    "\n",
    "%time char_vectorizer.fit(X_all)\n",
    "%time X_train_char = char_vectorizer.transform(X_train)\n",
    "%time X_test_char = char_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.48 s, sys: 99.8 ms, total: 6.58 s\n",
      "Wall time: 6.58 s\n",
      "CPU times: user 3.58 s, sys: 55.6 ms, total: 3.64 s\n",
      "Wall time: 3.64 s\n",
      "CPU times: user 3.56 s, sys: 60.2 ms, total: 3.62 s\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "                             strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "                             ngram_range=(1, 2), use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "                             stop_words='english')\n",
    "\n",
    "# word_vectorizer = TfidfVectorizer(\n",
    "#     sublinear_tf=True,\n",
    "#     strip_accents='unicode',\n",
    "#     analyzer='word',\n",
    "#     token_pattern=r'\\w{1,}',\n",
    "#     ngram_range=(1, 1),\n",
    "#     max_features=20000)\n",
    "    \n",
    "\n",
    "%time word_vectorizer.fit(X_all)\n",
    "%time X_train_word = word_vectorizer.transform(X_train)\n",
    "%time X_test_word = word_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train = hstack([X_train_char, X_train_word])\n",
    "X_test = hstack([X_test_char, X_test_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, \n",
    "                         C=1, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         class_weight=None, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Fold CV Score:  0.961094656\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "score = np.mean(cross_validation.cross_val_score(model, X_train, y_train, cv=20, scoring='roc_auc'))\n",
    "print (\"20 Fold CV Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "#result = model.predict(X_test)\n",
    "#result = model.predict_proba(X_test) \n",
    "result = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99203488,  0.03665503,  0.52460254, ...,  0.13763411,\n",
       "        0.94295881,  0.62267839])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now()\n",
    "current_time = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "description = \"Bag_of_Words_model\"\n",
    "\n",
    "output.to_csv(\"submissions/{description}_{time}_{score:.5f}.csv\".format(description=description, score=score, time=current_time), index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score / kaggle\n",
    "* baseline : 0.957149184 / 0.95358\n",
    "* 0.957798912 / 0.88460\n",
    "* 0.958188416 / 0.88516 - predict\n",
    "* 0.958188416 / 0.95405 - fit(X_all), predict_proba\n",
    "* 0.958357888 / 0.95440 - n't -> not\n",
    "* 0.958798464 / 0.95647 - char/word tf-idf\n",
    "* 0.961166976 / 0.95859 - char/word tf-idf, parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
